{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########## REQUIRE A API KEY FROM ALPHA VANTAGE (FREE)<br><br>\n",
    "This script is the extract the historical stock prices from the Alpha Vantage API.<br>\n",
    "Since the API for free users is limited, the definitions (in the last cell) will have to be ran one at a time,\n",
    "one per day...<br><br>\n",
    "Do note that in the last two lines, the dataframes are empty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, json, numpy, requests, os, datetime, pytz, time, re\n",
    "\n",
    "# 1. I want to obtain data on stocks, mainly focusing on historical data. ------------------------------------------\n",
    "### To use API functions and automation using loops, I need to create a list of the ticks I want to obtain data from:\n",
    "\n",
    "# I obtained the following list of ticks as a txt from http://www.eoddata.com/symbols.aspx from the New York Stock Exchange and the American Stock Exchange:\n",
    "NYSE_csv = pandas.read_csv('NYSE.txt', sep=\"\\t\", header=0).set_index('Symbol')\n",
    "NYSE_csv.to_csv('NYSE_csv.csv')\n",
    "\n",
    "AMEX_csv = pandas.read_csv('AMEX.txt', sep=\"\\t\", header=0).set_index('Symbol')\n",
    "AMEX_csv.to_csv('AMEX_csv.csv')\n",
    "\n",
    "# The two csv files creates were only made to check the structure of the datasets.\n",
    "# Merge the two DataFrames and ordering according to ticks alphabetically.\n",
    "# Removing all ticks with \"-\" or \".\" because the data for those are not provided by the Alpha Vantage API.\n",
    "# Removing these ticks will also prevent errors from occuring when requesting obtaining errors from API.\n",
    "stock_exchange_ticks_and_names = pandas.merge(NYSE_csv.reset_index(), AMEX_csv.reset_index(), how='outer')\n",
    "stock_exchange_ticks_and_names.to_csv('merged_NYSE_AMEX.csv')\n",
    "stock_exchange_ticks_and_names_copy = stock_exchange_ticks_and_names.copy().dropna()\n",
    "\n",
    "## Removing companies with special characters or the \"Cl A\" and \"Cl B\" = class A/B stocks\n",
    "regex1 = re.compile('[@_!#$%^&*()<>?/\\|}{~:[\\].]')\n",
    "regex2 = re.compile('Cl ')\n",
    "\n",
    "stock_exchange_ticks_and_names_removed = pandas.DataFrame()\n",
    "\n",
    "for x, y in stock_exchange_ticks_and_names_copy.iterrows():\n",
    "\n",
    "    if bool(regex1.search(y['Description'])) == False and bool(regex2.search(y['Description'])) == False and bool(regex1.search(y['Symbol'])) == False:\n",
    "        stock_exchange_ticks_and_names_removed.loc[x, 'Symbol'] = y['Symbol']\n",
    "        stock_exchange_ticks_and_names_removed.loc[x, 'Description'] = y['Description']\n",
    "\n",
    "stock_exchange_ticks_and_names_removed = stock_exchange_ticks_and_names_removed.set_index('Symbol')\n",
    "stock_exchange_ticks_and_names_removed = stock_exchange_ticks_and_names_removed.reset_index()\n",
    "stock_exchange_ticks_and_names_removed.to_csv('merged_NYSE_AMEX_removed_alpha.csv')\n",
    "\n",
    "\n",
    "# Looping through Alpha Vantage API to obtain historical data for the last 20 years\n",
    "## Due to restrictions on daily requests, only 500 requests to the API can be made\n",
    "## per day and 5 requests per minute. I created smaller DataFrames out of \n",
    "## stock_exchange_ticks_and_names to lessen the time it takes to run the requests, as well as\n",
    "## prevent the gathering repeats of the same ticks--should the requests get interrupted.\n",
    "### This part of the code will create a new csv file for each tick to eliminate the need to \n",
    "### creating one large DataFrame with the data from all 148 ticks.\n",
    "stock_exchange_ticks_and_names_0_399 = stock_exchange_ticks_and_names_removed.iloc[0:400, :]\n",
    "stock_exchange_ticks_and_names_400_799 = stock_exchange_ticks_and_names_removed.iloc[400:800, :]\n",
    "stock_exchange_ticks_and_names_800_1199 = stock_exchange_ticks_and_names_removed.iloc[800:1200, :]\n",
    "stock_exchange_ticks_and_names_1200_1599 = stock_exchange_ticks_and_names_removed.iloc[1200:1600, :]\n",
    "stock_exchange_ticks_and_names_1600_1999 = stock_exchange_ticks_and_names_removed.iloc[1600:2000, :]\n",
    "stock_exchange_ticks_and_names_2000_2399 = stock_exchange_ticks_and_names_removed.iloc[2000:2400, :]\n",
    "stock_exchange_ticks_and_names_2400_2799 = stock_exchange_ticks_and_names_removed.iloc[2400:2800, :]\n",
    "stock_exchange_ticks_and_names_2800_3199 = stock_exchange_ticks_and_names_removed.iloc[2800:3200, :]\n",
    "stock_exchange_ticks_and_names_3200_3599 = stock_exchange_ticks_and_names_removed.iloc[3200:3600, :]\n",
    "stock_exchange_ticks_and_names_3600_3999 = stock_exchange_ticks_and_names_removed.iloc[3600:4000, :]\n",
    "stock_exchange_ticks_and_names_4000_4399 = stock_exchange_ticks_and_names_removed.iloc[4000:4400, :]\n",
    "stock_exchange_ticks_and_names_4400_4799 = stock_exchange_ticks_and_names_removed.iloc[4400:4800, :]\n",
    "stock_exchange_ticks_and_names_4800_4880 = stock_exchange_ticks_and_names_removed.iloc[4800:, :]\n",
    "\n",
    "stock_indices_df = pandas.DataFrame({'Description': ['S&P', 'Dow', \"Nasdaq\"], 'Symbol': ['.INX', '.DJI', \".IXIC\"]})\n",
    "\n",
    "\n",
    "def daily_stock_request(stock_ticks_names):\n",
    "    filepath = os.getcwd() + '\\\\Daily Stock Prices\\\\'\n",
    "    working_stocks = []\n",
    "\n",
    "    for x, z in stock_ticks_names.iterrows():\n",
    "        print(z['Symbol'])  ### This is to indicate where a error might have occurred.\n",
    "        try:\n",
    "            get_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=' + z['Symbol'] + '&outputsize=full&dataype=json&apikey=' ### INPUT API KEY\n",
    "            alpha_vantage_api_requests = requests.get(get_URL)\n",
    "            alpha_vantage_api_convert = alpha_vantage_api_requests.json()\n",
    "\n",
    "            time.sleep(20)\n",
    "\n",
    "            if 'Time Series (Daily)' in alpha_vantage_api_convert.keys():\n",
    "                daily_stock_df = pandas.DataFrame()\n",
    "                date_list = list(alpha_vantage_api_convert['Time Series (Daily)'].keys())\n",
    "\n",
    "                for y, u in zip(date_list, range(len(date_list))):\n",
    "                    daily_stock_df.loc[u, 'Symbol'] = z['Symbol']\n",
    "                    daily_stock_df.loc[u, 'Name'] = z['Description']\n",
    "                    daily_stock_df.loc[u, 'Date'] = y\n",
    "                    daily_stock_df.loc[u, 'Open'] = alpha_vantage_api_convert['Time Series (Daily)'][y]['1. open']\n",
    "                    daily_stock_df.loc[u, 'High'] = alpha_vantage_api_convert['Time Series (Daily)'][y]['2. high']\n",
    "                    daily_stock_df.loc[u, 'Low'] = alpha_vantage_api_convert['Time Series (Daily)'][y]['3. low']\n",
    "                    daily_stock_df.loc[u, 'Close'] = alpha_vantage_api_convert['Time Series (Daily)'][y]['4. close']\n",
    "                    daily_stock_df.loc[u, 'Volume'] = alpha_vantage_api_convert['Time Series (Daily)'][y]['5. volume']\n",
    "                print('8')\n",
    "                \n",
    "                if not os.path.exists(filepath):\n",
    "                    os.makedirs(filepath)\n",
    "\n",
    "                ### Updates the current .csv file with the new dates if it already exists.\n",
    "                if os.path.exists(filepath + z['Symbol'] + ' - ' + z['Description'] + '.csv') == True:\n",
    "                    temp_df = pandas.read_csv(filepath + z['Symbol'] + ' - ' + z['Description'] + '.csv')\n",
    "                    print('4')\n",
    "                    if temp_df.Date.max() < daily_stock_df.Date.max():\n",
    "                        print('1')\n",
    "                        difference_df = daily_stock_df[daily_stock_df.Date > temp_df.Date.max()]\n",
    "                        print('2')\n",
    "                        master_df = pandas.concat([temp_df, difference_df]).sort_values(by='Date', ascending=False)\n",
    "                        print('3')\n",
    "                        master_df.to_csv(filepath + z['Symbol'] + ' - ' + z['Description'] + '.csv')\n",
    "                    working_stocks.append(z['Description'])\n",
    "                    print(working_stocks)\n",
    "                print('7')\n",
    "                if os.path.exists(filepath + z['Symbol'] + ' - ' + z['Description'] + '.csv') == False:\n",
    "                    print('6')\n",
    "                    daily_stock_df.to_csv(filepath + z['Symbol'] + ' - ' + z['Description'] + '.csv')\n",
    "                    working_stocks.append(z['Description'])\n",
    "                    print(working_stocks)\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return working_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_stock_request(stock_indices_df)  ## Run everytime; Nasdaq does not return any data even after different changes\n",
    "\n",
    "working_stocks1 = daily_stock_request(stock_exchange_ticks_and_names_0_399)  # 390 stocks working\n",
    "working_stocks2 = daily_stock_request(stock_exchange_ticks_and_names_400_799) # 399 stocks working\n",
    "working_stocks3 = daily_stock_request(stock_exchange_ticks_and_names_800_1199) # 398 stocks working\n",
    "working_stocks4 = daily_stock_request(stock_exchange_ticks_and_names_1200_1599) # 400 stocks working\n",
    "working_stocks5 = daily_stock_request(stock_exchange_ticks_and_names_1600_1999) # 387 stocks working\n",
    "working_stocks6 = daily_stock_request(stock_exchange_ticks_and_names_2000_2399) # 388  stocks working\n",
    "working_stocks7 = daily_stock_request(stock_exchange_ticks_and_names_2400_2799) # 388 stocks working\n",
    "working_stocks8 = daily_stock_request(stock_exchange_ticks_and_names_2800_3199) # 395 stocks working\n",
    "working_stocks9 = daily_stock_request(stock_exchange_ticks_and_names_3200_3599) # 398 stocks working\n",
    "working_stocks10 = daily_stock_request(stock_exchange_ticks_and_names_3600_3999) # 396 stocks working\n",
    "working_stocks11 = daily_stock_request(stock_exchange_ticks_and_names_4000_4399) # 81 stocks working (only 81 stocks in df)\n",
    "working_stocks12 = daily_stock_request(stock_exchange_ticks_and_names_4400_4799) # no stocks in df\n",
    "working_stocks13 = daily_stock_request(stock_exchange_ticks_and_names_4800_4880) # no stocks in df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
