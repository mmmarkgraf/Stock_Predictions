{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, json, numpy, requests, os, datetime, statistics, math, pytz, tweepy, sqlite3, time, re, random, matplotlib.pyplot as plt, sklearn, statsmodels.api as sm\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script merges parts of csv into a final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df_maker(symbol, name):\n",
    "    try:\n",
    "        ## Patterns_Score DataFrame will be the foundation DataFrame since it has the price data already included.\n",
    "        patterns_df = pandas.read_csv(os.getcwd() + '\\\\Patterns Score\\\\'  + symbol + ' - ' + name + ' - Patterns Score.csv', index_col= 'Date', parse_dates= True)\n",
    "        patterns_df = patterns_df.sort_index(ascending=True)\n",
    "        merged_df = patterns_df.copy()\n",
    "\n",
    "        print(symbol)\n",
    "\n",
    "        base_5_df = pandas.read_csv(os.getcwd() + '\\\\Base Score\\\\'  + symbol + ' - ' + name + ' - Base Score - 5 Days.csv', index_col= 'Date', parse_dates= True)\n",
    "\n",
    "        base_7_df = pandas.read_csv(os.getcwd() + '\\\\Base Score\\\\'  + symbol + ' - ' + name + ' - Base Score - 7 Days.csv', index_col= 'Date', parse_dates= True)\n",
    "\n",
    "        base_10_df = pandas.read_csv(os.getcwd() + '\\\\Base Score\\\\'  + symbol + ' - ' + name + ' - Base Score - 10 Day.csv', index_col= 'Date', parse_dates= True)\n",
    "\n",
    "        base_summary_df = pandas.read_csv(os.getcwd() + '\\\\Base Score\\\\'  + symbol + ' - ' + name + ' - Base Score - Summary.csv', index_col= 'Date', parse_dates= True)\n",
    "\n",
    "        earnings_df = pandas.DataFrame()\n",
    "\n",
    "        times_df = pandas.DataFrame()\n",
    "        google_df = pandas.DataFrame()\n",
    "\n",
    "        times_exist = 0\n",
    "        google_exist = 0\n",
    "\n",
    "        if os.path.exists(os.getcwd() + '\\\\Earnings\\\\' + symbol + ' - '+ name +' - Earnings - 2016-2020.csv') == True:\n",
    "            earnings_df = pandas.read_csv(os.getcwd() + '\\\\Earnings\\\\' + symbol + ' - '+ name +' - Earnings - 2016-2020.csv', index_col= 'Date', parse_dates= True)\n",
    "\n",
    "        if os.path.exists(os.getcwd() + '\\\\Historical Articles\\\\' + name +'.csv') == True:\n",
    "            times_df = pandas.read_csv(os.getcwd() + '\\\\Historical Articles\\\\' + name +'.csv')\n",
    "\n",
    "            if 'Text_Value' in times_df.columns:\n",
    "                times_exist = 1\n",
    "\n",
    "        if os.path.exists(os.getcwd() + '\\\\Google Search - News\\\\' + name +'.csv') == True:\n",
    "            google_df = pandas.read_csv(os.getcwd() + '\\\\Google Search - News\\\\' + name +'.csv')\n",
    "\n",
    "            if 'Text_Value' in google_df.columns:\n",
    "                google_exist = 1\n",
    "\n",
    "        date_extract = re.compile('\\d{4}-\\d{2}-\\d{2}')\n",
    "\n",
    "        if times_exist == 1 and google_exist == 1:\n",
    "            for q in [times_df, google_df]:\n",
    "                for p, r in q.iterrows():\n",
    "                    q.pub_date[p] = date_extract.match(r.pub_date).group(0)\n",
    "\n",
    "            times_summary_df = pandas.DataFrame({'Date': list(times_df.groupby(['pub_date']).count().index), 'Number_Of_Times_Articles': list(times_df.groupby(['pub_date']).count().headline), 'Times_Score': list(times_df.groupby(['pub_date']).sum().Text_Value)})\n",
    "            times_summary_df.Date = pandas.to_datetime(times_summary_df.Date)\n",
    "\n",
    "            google_summary_df = pandas.DataFrame({'Date': list(google_df.groupby(['pub_date']).count().index), 'Number_Of_Google_Articles': list(google_df.groupby(['pub_date']).count().Company), 'Google_Score': list(google_df.groupby(['pub_date']).sum().Text_Value)})\n",
    "            google_summary_df.Date = pandas.to_datetime(google_summary_df.Date)\n",
    "\n",
    "        elif times_exist == 1 and google_exist != 1:\n",
    "            for p, r in times_df.iterrows():\n",
    "                times_df.pub_date[p] = date_extract.match(r.pub_date).group(0)\n",
    "\n",
    "            times_summary_df = pandas.DataFrame({'Date': list(times_df.groupby(['pub_date']).count().index), 'Number_Of_Times_Articles': list(times_df.groupby(['pub_date']).count().headline), 'Times_Score': list(times_df.groupby(['pub_date']).sum().Text_Value)})\n",
    "            times_summary_df.Date = pandas.to_datetime(times_summary_df.Date)\n",
    "\n",
    "        elif times_exist != 1 and google_exist == 1:\n",
    "            for p, r in google_df.iterrows():\n",
    "                google_df.pub_date[p] = date_extract.match(r.pub_date).group(0)\n",
    "\n",
    "            google_summary_df = pandas.DataFrame({'Date': list(google_df.groupby(['pub_date']).count().index), 'Number_Of_Google_Articles': list(google_df.groupby(['pub_date']).count().Company), 'Google_Score': list(google_df.groupby(['pub_date']).sum().Text_Value)})\n",
    "            google_summary_df.Date = pandas.to_datetime(google_summary_df.Date)\n",
    "\n",
    "\n",
    "        ### Merging columns:\n",
    "        temp_df = merged_df.merge(base_5_df.Base_Score, how='left', left_on=merged_df.index, right_on=base_5_df.index)\n",
    "        temp_df = temp_df.merge(base_7_df.Base_Score, how='left', left_on='key_0', right_on=base_7_df.index)\n",
    "        temp_df = temp_df.merge(base_10_df.Base_Score, how='left', left_on='key_0', right_on=base_10_df.index)\n",
    "        temp_df = temp_df.merge(base_summary_df.Trend, how='left', left_on='key_0', right_on=base_summary_df.index)\n",
    "        temp_df = temp_df.merge(base_summary_df.Average_Slope, how='left', left_on='key_0', right_on=base_summary_df.index)\n",
    "        temp_df = temp_df.merge(base_summary_df.Predicted_Value_For_End_Date, how='left', left_on='key_0', right_on=base_summary_df.index)\n",
    "\n",
    "\n",
    "        if os.path.exists(os.getcwd() + '\\\\Earnings\\\\' + symbol + ' - '+ name +' - Earnings - 2016-2020.csv') == False:\n",
    "            temp_df['Earnings_Score'] = numpy.NaN\n",
    "            temp_df['EPS_Estimate'] = numpy.NaN\n",
    "            temp_df['EPS_Reported'] = numpy.NaN\n",
    "            temp_df['Surprise_Percentage'] = numpy.NaN\n",
    "            temp_df['Surprise_Overall_Average'] = numpy.NaN\n",
    "\n",
    "        else:\n",
    "            temp_df = temp_df.merge(earnings_df[['Earnings_Score', 'EPS_Estimate', 'EPS_Reported', 'Surprise_Percentage', 'Surprise_Overall_Average']], how='left', left_on='key_0', right_on=earnings_df.index)\n",
    "\n",
    "\n",
    "        if times_exist != 1:\n",
    "            temp_df['Number_Of_Times_Articles'] = numpy.NaN\n",
    "            temp_df['NYTimes_Score'] = numpy.NaN\n",
    "\n",
    "        else:\n",
    "            temp_df = temp_df.merge(times_summary_df[['Number_Of_Times_Articles', 'Times_Score']], how='left', left_on='key_0', right_on=times_summary_df.Date)\n",
    "\n",
    "        if google_exist != 1:\n",
    "            temp_df['Number_Of_Google_Articles'] = numpy.NaN\n",
    "            temp_df['Google_Score'] = numpy.NaN\n",
    "\n",
    "        else:\n",
    "            temp_df = temp_df.merge(google_summary_df[['Number_Of_Google_Articles', 'Google_Score']], how='left', left_on='key_0', right_on=google_summary_df.Date)\n",
    "\n",
    "\n",
    "        temp_df = temp_df[temp_df.columns.drop(list(temp_df.filter(regex='Unnamed')))]\n",
    "\n",
    "        temp_df.columns = ['Date', 'Symbol', 'Name', 'Open', 'High',\n",
    "               'Low', 'Close', 'Volume', 'SMA_30', 'SMA_60', 'Patterns_Score',\n",
    "               'Base_Score_5', 'Base_Score_7', 'Base_Score_10', 'Trend', 'Average_Slope_5_7_10',\n",
    "               'Predicted_Value_For_End_Date', 'Earnings_Score', 'EPS_Estimate',\n",
    "               'EPS_Reported', 'Surprise_Percentage', 'Surprise_Overall_Average',\n",
    "               'Number_Of_Times_Articles', 'NYTimes_Score',\n",
    "               'Number_Of_Google_Articles', 'Google_Score']\n",
    "\n",
    "        merged_df = temp_df.copy()\n",
    "\n",
    "        final_df = merged_df.copy()\n",
    "\n",
    "        final_df = final_df.loc[:, ['Date', 'Symbol', 'Name', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "               'SMA_30', 'SMA_60', 'Patterns_Score', 'Base_Score_5', 'Base_Score_7',\n",
    "               'Base_Score_10', 'Trend', 'Average_Slope_5_7_10',\n",
    "               'Predicted_Value_For_End_Date', 'Earnings_Score', \n",
    "               'Number_Of_Times_Articles', 'NYTimes_Score',\n",
    "               'Number_Of_Google_Articles', 'Google_Score']]\n",
    "\n",
    "        final_df = final_df.fillna(0)\n",
    "\n",
    "        if not os.path.exists(os.getcwd() + '\\\\Final DataFrame\\\\'):\n",
    "            os.makedirs(os.getcwd() + '\\\\Final DataFrame\\\\')\n",
    "\n",
    "        merged_df.to_csv(os.getcwd() + '\\\\Final DataFrame\\\\'  + symbol + ' - ' + name + ' - Summary.csv')\n",
    "        final_df.to_csv(os.getcwd() + '\\\\Final DataFrame\\\\'  + symbol + ' - ' + name + ' - Final DataFrame.csv')\n",
    "    \n",
    "    except Exception:\n",
    "        print('Error: ', symbol)\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looping:\n",
    "stocks_and_names_with_indices = pandas.read_csv('merged_NYSE_AMEX_removed_intercept_pattern.csv')\n",
    "\n",
    "for x, y in stocks_and_names_with_indices.iterrows():\n",
    "    try:\n",
    "        final_df_maker(symbol=y['Symbol'], name=y['Description'])  \n",
    "        \n",
    "    except Exception:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
