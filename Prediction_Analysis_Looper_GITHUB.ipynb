{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, json, numpy, requests, os, datetime, statistics, math, pytz, tweepy, sqlite3, time, re, random, matplotlib.pyplot as plt, sklearn, statsmodels.api as sm, seaborn\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is to analyze the csv file created in the Price_Predict script (\"Prediction Summary\" files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_analysis(symbol, name):\n",
    "    prediction_summary = pandas.read_csv(os.getcwd() + '\\\\Predictions\\\\'  + symbol + ' - ' + name + ' - Prediction Summary.csv', index_col= 'Predicted_Date', parse_dates= True).sort_index(ascending=True)\n",
    "\n",
    "    ### Want to splice the newest model best parameters:\n",
    "    prediction_summary_selected = prediction_summary.iloc[[len(prediction_summary)-1]]\n",
    "\n",
    "    ### Extracting and assigning the best tress:\n",
    "    Random_Forest_Shuffled_Best_Trees = prediction_summary_selected.Random_Forest_Shuffled_Best_Trees[0]\n",
    "\n",
    "    Random_Forest_Ordered_Best_Trees = prediction_summary_selected.Random_Forest_Ordered_Best_Trees[0]\n",
    "\n",
    "    Random_Forest_Ordered_No_Bootstrap_Best_Trees = prediction_summary_selected.Random_Forest_Ordered_No_Bootstrap_Best_Trees[0]\n",
    "\n",
    "    AdaBoost_Shuffled_Best_Trees = prediction_summary_selected.AdaBoost_Shuffled_Best_Trees[0]\n",
    "\n",
    "    AdaBoost_Ordered_Best_Trees = prediction_summary_selected.AdaBoost_Ordered_Best_Trees[0]\n",
    "\n",
    "    Gradient_Boosting_Shuffled_Best_Trees = prediction_summary_selected.Gradient_Boosting_Shuffled_Best_Trees[0]\n",
    "\n",
    "    Gradient_Boosting_Ordered_Best_Trees = prediction_summary_selected.Gradient_Boosting_Ordered_Best_Trees[0]\n",
    "\n",
    "    ### Modified version from the Price_Predict script:\n",
    "    final_df = pandas.read_csv(os.getcwd() + '\\\\Final DataFrame\\\\'  + symbol + ' - ' + name + ' - Final DataFrame.csv', index_col= 'Date', parse_dates= True).sort_index(ascending=True)\n",
    "    final_df = final_df.drop(['Unnamed: 0', 'Symbol', 'Name'], axis= 1)\n",
    "\n",
    "    print(symbol, name)\n",
    "\n",
    "    df_counter = 0\n",
    "\n",
    "    for u, v in final_df.iterrows():\n",
    "\n",
    "        if v.name != final_df.index[-1]:\n",
    "            final_df.loc[u, 'Label'] = final_df.iloc[df_counter+1]['Close']\n",
    "\n",
    "        if v.Trend == 'High Uptrend':\n",
    "            final_df.loc[u, 'Trend'] = 3\n",
    "\n",
    "        elif v.Trend == 'Uptrend':\n",
    "            final_df.loc[u, 'Trend'] = 2\n",
    "\n",
    "        elif v.Trend == 'Slight Uptrend':\n",
    "            final_df.loc[u, 'Trend'] = 1\n",
    "\n",
    "        elif v.Trend == 'No Trend':\n",
    "            final_df.loc[u, 'Trend'] = 0\n",
    "\n",
    "        elif v.Trend == 'Slight Downtrend':\n",
    "            final_df.loc[u, 'Trend'] = -1\n",
    "\n",
    "        elif v.Trend == 'Downtrend':\n",
    "            final_df.loc[u, 'Trend'] = -2\n",
    "\n",
    "        elif v.Trend == 'High Downtrend':\n",
    "            final_df.loc[u, 'Trend'] = -3\n",
    "\n",
    "        df_counter += 1\n",
    "\n",
    "    final_df = final_df.drop_duplicates()\n",
    "\n",
    "    ##### Because the last day on the df will not be labeled, it will need to be removed.\n",
    "    final_df_last_row = final_df.iloc[[-1]]\n",
    "    final_df_last_row = final_df_last_row.drop('Label', axis= 1)\n",
    "\n",
    "    final_df = final_df.drop(final_df.index[-1], axis= 0)\n",
    "\n",
    "    ### Splitting the label from the variables:\n",
    "    ##### The first 5 rows do not have the 5, 7, or 10 day slopes and the modeling should not be affected since there are many \n",
    "    ##### data points avaliable for most stocks\n",
    "    y = final_df.iloc[5:, 19]\n",
    "    X = final_df.iloc[5:, :19]\n",
    "\n",
    "    ## The reordering of the index is to include the newest dates, which has more data on the current market (coronavirus), when\n",
    "    ## splitting with shuffle = False--forcing the train data to include the newest dates. \n",
    "    ## This should not affect if shuffle = True.\n",
    "    y = y.sort_index(ascending=False)\n",
    "    X = X.sort_index(ascending=False)\n",
    "\n",
    "    ### Splitting the data: test_size = default = 0.25\n",
    "    shuffled_X_train, shuffled_X_test, shuffled_y_train, shuffled_y_test = train_test_split(X, y)\n",
    "\n",
    "    ordered_X_train, ordered_X_test, ordered_y_train, ordered_y_test = train_test_split(X, y, shuffle= False)\n",
    "\n",
    "    ordered_X_train = ordered_X_train.sort_index(ascending=True)\n",
    "    ordered_X_test = ordered_X_test.sort_index(ascending=True)\n",
    "    ordered_y_train = ordered_y_train.sort_index(ascending=True)\n",
    "    ordered_y_test = ordered_y_test.sort_index(ascending=True)\n",
    "\n",
    "    ########## Changes from Price_Predict start here:------------------------------------------------------------------------------\n",
    "    ### All modeling is set to one parameter and .predict method is done on all X observations for visual comparison\n",
    "    ### as well as statistical comparison between the difference models\n",
    "\n",
    "\n",
    "    # The last unlabeled row is added with the X:\n",
    "\n",
    "    X_plus_last = pandas.concat([X, final_df_last_row]).sort_index(ascending=True)\n",
    "\n",
    "    ### Random Forest:\n",
    "    #### According to a Harvard lecture, random forest for regression should have max_features = 'sqrt' else the default ('auto')\n",
    "    #### will do bagging instead of random forest\n",
    "\n",
    "    random_forest = RandomForestRegressor(n_estimators= Random_Forest_Shuffled_Best_Trees, max_features= 'sqrt')\n",
    "    random_forest.fit(shuffled_X_train, shuffled_y_train)\n",
    "\n",
    "    best_random_forest_accuracy_score_shuffled = random_forest.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_random_forest_predict_shuffled = random_forest.predict(X_plus_last)\n",
    "\n",
    "    features_df = pandas.DataFrame({'RF_Shuffled_Open': random_forest.feature_importances_[0], \n",
    "                                    'RF_Shuffled_High': random_forest.feature_importances_[1], \n",
    "                                    'RF_Shuffled_Low': random_forest.feature_importances_[2], \n",
    "                                    'RF_Shuffled_Close': random_forest.feature_importances_[3], \n",
    "                                    'RF_Shuffled_Volume': random_forest.feature_importances_[4], \n",
    "                                    'RF_Shuffled_SMA_30': random_forest.feature_importances_[5], \n",
    "                                    'RF_Shuffled_SMA_60': random_forest.feature_importances_[6], \n",
    "                                    'RF_Shuffled_Patterns_Score': random_forest.feature_importances_[7], \n",
    "                                    'RF_Shuffled_Base_Score_5': random_forest.feature_importances_[8], \n",
    "                                    'RF_Shuffled_Base_Score_7': random_forest.feature_importances_[9], \n",
    "                                    'RF_Shuffled_Base_Score_10': random_forest.feature_importances_[10], \n",
    "                                    'RF_Shuffled_Trend': random_forest.feature_importances_[11], \n",
    "                                    'RF_Shuffled_Average_Slope_5_7_10': random_forest.feature_importances_[12], \n",
    "                                    'RF_Shuffled_Predicted_Value_For_End_Date': random_forest.feature_importances_[13], \n",
    "                                    'RF_Shuffled_Earnings_Score': random_forest.feature_importances_[14], \n",
    "                                    'RF_Shuffled_Number_Of_Times_Articles': random_forest.feature_importances_[15], \n",
    "                                    'RF_Shuffled_NYTimes_Score': random_forest.feature_importances_[16], \n",
    "                                    'RF_Shuffled_Number_Of_Google_Articles': random_forest.feature_importances_[17], \n",
    "                                    'RF_Shuffled_Google_Score': random_forest.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    features_df.index.names = ['Symbol']\n",
    "\n",
    "    random_forest = RandomForestRegressor(n_estimators= Random_Forest_Ordered_Best_Trees, max_features= 'sqrt')\n",
    "    random_forest.fit(ordered_X_train, ordered_y_train)\n",
    "\n",
    "    best_random_forest_accuracy_score_ordered = random_forest.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_random_forest_predict_ordered = random_forest.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'RF_Ordered_Open': random_forest.feature_importances_[0], \n",
    "                                'RF_Ordered_High': random_forest.feature_importances_[1], \n",
    "                                'RF_Ordered_Low': random_forest.feature_importances_[2], \n",
    "                                'RF_Ordered_Close': random_forest.feature_importances_[3], \n",
    "                                'RF_Ordered_Volume': random_forest.feature_importances_[4], \n",
    "                                'RF_Ordered_SMA_30': random_forest.feature_importances_[5], \n",
    "                                'RF_Ordered_SMA_60': random_forest.feature_importances_[6], \n",
    "                                'RF_Ordered_Patterns_Score': random_forest.feature_importances_[7], \n",
    "                                'RF_Ordered_Base_Score_5': random_forest.feature_importances_[8], \n",
    "                                'RF_Ordered_Base_Score_7': random_forest.feature_importances_[9], \n",
    "                                'RF_Ordered_Base_Score_10': random_forest.feature_importances_[10], \n",
    "                                'RF_Ordered_Trend': random_forest.feature_importances_[11], \n",
    "                                'RF_Ordered_Average_Slope_5_7_10': random_forest.feature_importances_[12], \n",
    "                                'RF_Ordered_Predicted_Value_For_End_Date': random_forest.feature_importances_[13], \n",
    "                                'RF_Ordered_Earnings_Score': random_forest.feature_importances_[14], \n",
    "                                'RF_Ordered_Number_Of_Times_Articles': random_forest.feature_importances_[15], \n",
    "                                'RF_Ordered_NYTimes_Score': random_forest.feature_importances_[16], \n",
    "                                'RF_Ordered_Number_Of_Google_Articles': random_forest.feature_importances_[17], \n",
    "                                'RF_Ordered_Google_Score': random_forest.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "    random_forest = RandomForestRegressor(n_estimators= Random_Forest_Ordered_No_Bootstrap_Best_Trees, max_features= 'sqrt', bootstrap= False)\n",
    "    random_forest.fit(ordered_X_train, ordered_y_train)\n",
    "\n",
    "    best_random_forest_accuracy_score_ordered_no_boot = random_forest.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_random_forest_predict_ordered_no_boot = random_forest.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'RF_Ordered_Open_No_Boot': random_forest.feature_importances_[0], \n",
    "                                'RF_Ordered_High_No_Boot': random_forest.feature_importances_[1], \n",
    "                                'RF_Ordered_Low_No_Boot': random_forest.feature_importances_[2], \n",
    "                                'RF_Ordered_Close_No_Boot': random_forest.feature_importances_[3], \n",
    "                                'RF_Ordered_Volume_No_Boot': random_forest.feature_importances_[4], \n",
    "                                'RF_Ordered_SMA_30_No_Boot': random_forest.feature_importances_[5], \n",
    "                                'RF_Ordered_SMA_60_No_Boot': random_forest.feature_importances_[6], \n",
    "                                'RF_Ordered_Patterns_Score_No_Boot': random_forest.feature_importances_[7], \n",
    "                                'RF_Ordered_Base_Score_5_No_Boot': random_forest.feature_importances_[8], \n",
    "                                'RF_Ordered_Base_Score_7_No_Boot': random_forest.feature_importances_[9], \n",
    "                                'RF_Ordered_Base_Score_10_No_Boot': random_forest.feature_importances_[10], \n",
    "                                'RF_Ordered_Trend_No_Boot': random_forest.feature_importances_[11], \n",
    "                                'RF_Ordered_Average_Slope_5_7_10_No_Boot': random_forest.feature_importances_[12], \n",
    "                                'RF_Ordered_Predicted_Value_For_End_Date_No_Boot': random_forest.feature_importances_[13], \n",
    "                                'RF_Ordered_Earnings_Score_No_Boot': random_forest.feature_importances_[14], \n",
    "                                'RF_Ordered_Number_Of_Times_Articles_No_Boot': random_forest.feature_importances_[15], \n",
    "                                'RF_Ordered_NYTimes_Score_No_Boot': random_forest.feature_importances_[16], \n",
    "                                'RF_Ordered_Number_Of_Google_Articles_No_Boot': random_forest.feature_importances_[17], \n",
    "                                'RF_Ordered_Google_Score_No_Boot': random_forest.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "\n",
    "    ### Testing AdaBoost:\n",
    "    ada = AdaBoostRegressor(n_estimators= AdaBoost_Shuffled_Best_Trees)\n",
    "    ada.fit(shuffled_X_train, shuffled_y_train)\n",
    "\n",
    "    best_ada_forest_accuracy_score_shuffled = ada.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_ada_predict_shuffled = ada.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'Ada_Shuffled_Open': ada.feature_importances_[0], \n",
    "                                'Ada_Shuffled_High': ada.feature_importances_[1], \n",
    "                                'Ada_Shuffled_Low': ada.feature_importances_[2], \n",
    "                                'Ada_Shuffled_Close': ada.feature_importances_[3], \n",
    "                                'Ada_Shuffled_Volume': ada.feature_importances_[4], \n",
    "                                'Ada_Shuffled_SMA_30': ada.feature_importances_[5], \n",
    "                                'Ada_Shuffled_SMA_60': ada.feature_importances_[6], \n",
    "                                'Ada_Shuffled_Patterns_Score': ada.feature_importances_[7], \n",
    "                                'Ada_Shuffled_Base_Score_5': ada.feature_importances_[8], \n",
    "                                'Ada_Shuffled_Base_Score_7': ada.feature_importances_[9], \n",
    "                                'Ada_Shuffled_Base_Score_10': ada.feature_importances_[10], \n",
    "                                'Ada_Shuffled_Trend': ada.feature_importances_[11], \n",
    "                                'Ada_Shuffled_Average_Slope_5_7_10': ada.feature_importances_[12], \n",
    "                                'Ada_Shuffled_Predicted_Value_For_End_Date': ada.feature_importances_[13], \n",
    "                                'Ada_Shuffled_Earnings_Score': ada.feature_importances_[14], \n",
    "                                'Ada_Shuffled_Number_Of_Times_Articles': ada.feature_importances_[15], \n",
    "                                'Ada_Shuffled_NYTimes_Score': ada.feature_importances_[16], \n",
    "                                'Ada_Shuffled_Number_Of_Google_Articles': ada.feature_importances_[17], \n",
    "                                'Ada_Shuffled_Google_Score': ada.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "\n",
    "    ada = AdaBoostRegressor(n_estimators= AdaBoost_Ordered_Best_Trees)\n",
    "    ada.fit(ordered_X_train, ordered_y_train)\n",
    "\n",
    "    best_ada_accuracy_score_ordered = ada.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_ada_predict_ordered = ada.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'Ada_Ordered_Open': ada.feature_importances_[0], \n",
    "                                'Ada_Ordered_High': ada.feature_importances_[1], \n",
    "                                'Ada_Ordered_Low': ada.feature_importances_[2], \n",
    "                                'Ada_Ordered_Close': ada.feature_importances_[3], \n",
    "                                'Ada_Ordered_Volume': ada.feature_importances_[4], \n",
    "                                'Ada_Ordered_SMA_30': ada.feature_importances_[5], \n",
    "                                'Ada_Ordered_SMA_60': ada.feature_importances_[6], \n",
    "                                'Ada_Ordered_Patterns_Score': ada.feature_importances_[7], \n",
    "                                'Ada_Ordered_Base_Score_5': ada.feature_importances_[8], \n",
    "                                'Ada_Ordered_Base_Score_7': ada.feature_importances_[9], \n",
    "                                'Ada_Ordered_Base_Score_10': ada.feature_importances_[10], \n",
    "                                'Ada_Ordered_Trend': ada.feature_importances_[11], \n",
    "                                'Ada_Ordered_Average_Slope_5_7_10': ada.feature_importances_[12], \n",
    "                                'Ada_Ordered_Predicted_Value_For_End_Date': ada.feature_importances_[13], \n",
    "                                'Ada_Ordered_Earnings_Score': ada.feature_importances_[14], \n",
    "                                'Ada_Ordered_Number_Of_Times_Articles': ada.feature_importances_[15], \n",
    "                                'Ada_Ordered_NYTimes_Score': ada.feature_importances_[16], \n",
    "                                'Ada_Ordered_Number_Of_Google_Articles': ada.feature_importances_[17], \n",
    "                                'Ada_Ordered_Google_Score': ada.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Testing Gradient Boosting: GradientBoostingRegressor\n",
    "    gradient_boosting = GradientBoostingRegressor(n_estimators= Gradient_Boosting_Shuffled_Best_Trees)\n",
    "    gradient_boosting.fit(shuffled_X_train, shuffled_y_train)\n",
    "\n",
    "    best_gradient_boosting_accuracy_score_shuffled = gradient_boosting.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_gradient_boosting_predict_shuffled = gradient_boosting.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'Gradient_Boosting_Shuffled_Open': gradient_boosting.feature_importances_[0], \n",
    "                                'Gradient_Boosting_Shuffled_High': gradient_boosting.feature_importances_[1], \n",
    "                                'Gradient_Boosting_Shuffled_Low': gradient_boosting.feature_importances_[2], \n",
    "                                'Gradient_Boosting_Shuffled_Close': gradient_boosting.feature_importances_[3], \n",
    "                                'Gradient_Boosting_Shuffled_Volume': gradient_boosting.feature_importances_[4], \n",
    "                                'Gradient_Boosting_Shuffled_SMA_30': gradient_boosting.feature_importances_[5], \n",
    "                                'Gradient_Boosting_Shuffled_SMA_60': gradient_boosting.feature_importances_[6], \n",
    "                                'Gradient_Boosting_Shuffled_Patterns_Score': gradient_boosting.feature_importances_[7], \n",
    "                                'Gradient_Boosting_Shuffled_Base_Score_5': gradient_boosting.feature_importances_[8], \n",
    "                                'Gradient_Boosting_Shuffled_Base_Score_7': gradient_boosting.feature_importances_[9], \n",
    "                                'Gradient_Boosting_Shuffled_Base_Score_10': gradient_boosting.feature_importances_[10], \n",
    "                                'Gradient_Boosting_Shuffled_Trend': gradient_boosting.feature_importances_[11], \n",
    "                                'Gradient_Boosting_Shuffled_Average_Slope_5_7_10': gradient_boosting.feature_importances_[12], \n",
    "                                'Gradient_Boosting_Shuffled_Predicted_Value_For_End_Date': gradient_boosting.feature_importances_[13], \n",
    "                                'Gradient_Boosting_Shuffled_Earnings_Score': gradient_boosting.feature_importances_[14], \n",
    "                                'Gradient_Boosting_Shuffled_Number_Of_Times_Articles': gradient_boosting.feature_importances_[15], \n",
    "                                'Gradient_Boosting_Shuffled_NYTimes_Score': gradient_boosting.feature_importances_[16], \n",
    "                                'Gradient_Boosting_Shuffled_Number_Of_Google_Articles': gradient_boosting.feature_importances_[17], \n",
    "                                'Gradient_Boosting_Shuffled_Google_Score': gradient_boosting.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "\n",
    "    gradient_boosting = GradientBoostingRegressor(n_estimators= Gradient_Boosting_Ordered_Best_Trees)\n",
    "    gradient_boosting.fit(ordered_X_train, ordered_y_train)\n",
    "\n",
    "    best_gradient_boosting_accuracy_score_ordered = gradient_boosting.score(shuffled_X_test, shuffled_y_test)\n",
    "\n",
    "    best_gradient_boosting_predict_ordered = gradient_boosting.predict(X_plus_last)\n",
    "\n",
    "    temp_df = pandas.DataFrame({'Gradient_Boosting_Ordered_Open': gradient_boosting.feature_importances_[0], \n",
    "                                'Gradient_Boosting_Ordered_High': gradient_boosting.feature_importances_[1], \n",
    "                                'Gradient_Boosting_Ordered_Low': gradient_boosting.feature_importances_[2], \n",
    "                                'Gradient_Boosting_Ordered_Close': gradient_boosting.feature_importances_[3], \n",
    "                                'Gradient_Boosting_Ordered_Volume': gradient_boosting.feature_importances_[4], \n",
    "                                'Gradient_Boosting_Ordered_SMA_30': gradient_boosting.feature_importances_[5], \n",
    "                                'Gradient_Boosting_Ordered_SMA_60': gradient_boosting.feature_importances_[6], \n",
    "                                'Gradient_Boosting_Ordered_Patterns_Score': gradient_boosting.feature_importances_[7], \n",
    "                                'Gradient_Boosting_Ordered_Base_Score_5': gradient_boosting.feature_importances_[8], \n",
    "                                'Gradient_Boosting_Ordered_Base_Score_7': gradient_boosting.feature_importances_[9], \n",
    "                                'Gradient_Boosting_Ordered_Base_Score_10': gradient_boosting.feature_importances_[10], \n",
    "                                'Gradient_Boosting_Ordered_Trend': gradient_boosting.feature_importances_[11], \n",
    "                                'Gradient_Boosting_Ordered_Average_Slope_5_7_10': gradient_boosting.feature_importances_[12], \n",
    "                                'Gradient_Boosting_Ordered_Predicted_Value_For_End_Date': gradient_boosting.feature_importances_[13], \n",
    "                                'Gradient_Boosting_Ordered_Earnings_Score': gradient_boosting.feature_importances_[14], \n",
    "                                'Gradient_Boosting_Ordered_Number_Of_Times_Articles': gradient_boosting.feature_importances_[15], \n",
    "                                'Gradient_Boosting_Ordered_NYTimes_Score': gradient_boosting.feature_importances_[16], \n",
    "                                'Gradient_Boosting_Ordered_Number_Of_Google_Articles': gradient_boosting.feature_importances_[17], \n",
    "                                'Gradient_Boosting_Ordered_Google_Score': gradient_boosting.feature_importances_[18]}, index=[symbol])\n",
    "\n",
    "    temp_df.index.names = ['Symbol']\n",
    "\n",
    "    features_df = features_df.merge(temp_df, how='outer', on='Symbol')\n",
    "\n",
    "    ### Adding the labels (y/the close of the next day) back onto X, as well as the predictions:\n",
    "\n",
    "    predictions_df = X_plus_last.merge(y, how= 'left', left_on= 'Date', right_on='Date')\n",
    "\n",
    "    predictions_df['Best_Random_Forest_Predict_Shuffled'] = list(best_random_forest_predict_shuffled)\n",
    "    predictions_df['Best_Random_Forest_Predict_Ordered'] = list(best_random_forest_predict_ordered)\n",
    "    predictions_df['Best_Random_Forest_Predict_Ordered_No_Boot'] = list(best_random_forest_predict_ordered_no_boot)\n",
    "\n",
    "    predictions_df['Best_Ada_Predict_Shuffled'] = list(best_ada_predict_shuffled)\n",
    "    predictions_df['Best_Ada_Predict_Ordered'] = list(best_ada_predict_ordered)\n",
    "\n",
    "    predictions_df['Best_Gradient_Boosting_Predict_Shuffled'] = list(best_gradient_boosting_predict_shuffled)\n",
    "    predictions_df['Best_Gradient_Boosting_Predict_Ordered'] = list(best_gradient_boosting_predict_ordered)\n",
    "\n",
    "    for q, p in predictions_df.iterrows():\n",
    "        ### Averaging the predictions:\n",
    "        average_prediction = numpy.average([p['Best_Random_Forest_Predict_Shuffled'], p['Best_Random_Forest_Predict_Ordered'], p['Best_Random_Forest_Predict_Ordered_No_Boot'], p['Best_Ada_Predict_Shuffled'], p['Best_Ada_Predict_Ordered'], p['Best_Gradient_Boosting_Predict_Shuffled'], p['Best_Gradient_Boosting_Predict_Ordered']])\n",
    "        predictions_df.loc[q, 'Average_Prediction'] = average_prediction\n",
    "\n",
    "\n",
    "        ### Calculating the difference between the Label - Close:\n",
    "        Difference_Label_Close = p.Label - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Label_Close'] = Difference_Label_Close\n",
    "\n",
    "\n",
    "        ### Calculating the difference between the Average_Prediction - Close:\n",
    "        Difference_Prediction_Close = average_prediction - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Average_Close'] = Difference_Prediction_Close\n",
    "\n",
    "\n",
    "        ### Calculating the difference between the Label - Average_Prediction:\n",
    "        Difference_Label_Prediction = p.Label - average_prediction\n",
    "        predictions_df.loc[q, 'Difference_Label_Average'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'Average_Price_Direction'] = Price_Direction\n",
    "        \n",
    "        ### Calculating the difference between the Best_Random_Forest_Predict_Shuffled - Close:\n",
    "        Difference_Prediction_Close = p['Best_Random_Forest_Predict_Shuffled'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_RF_Shuffled_Close'] = Difference_Prediction_Close\n",
    "\n",
    "        ### Calculating the difference between the Label - Best_Random_Forest_Predict_Shuffled:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Random_Forest_Predict_Shuffled']\n",
    "        predictions_df.loc[q, 'Difference_Label_RF_Shuffled'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'RF_Shuffled_Price_Direction'] = Price_Direction\n",
    "        \n",
    "        ### Calculating the difference between the Best_Random_Forest_Predict_Ordered - Close:\n",
    "        Difference_Prediction_Close = p['Best_Random_Forest_Predict_Ordered'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_RF_Ordered_Close'] = Difference_Prediction_Close\n",
    "\n",
    "        ### Calculating the difference between the Label - Best_Random_Forest_Predict_Ordered - Label:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Random_Forest_Predict_Ordered']\n",
    "        predictions_df.loc[q, 'Difference_Label_RF_Ordered'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'RF_Ordered_Price_Direction'] = Price_Direction\n",
    "        \n",
    "        ### Calculating the difference between the Best_Random_Forest_Predict_Ordered_No_Boot - Close:\n",
    "        Difference_Prediction_Close = p['Best_Random_Forest_Predict_Ordered_No_Boot'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_RF_Ordered_No_Boot_Close'] = Difference_Prediction_Close\n",
    "\n",
    "        ### Calculating the difference between the Label - Best_Random_Forest_Predict_Ordered_No_Boot:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Random_Forest_Predict_Ordered_No_Boot']\n",
    "        predictions_df.loc[q, 'Difference_Label_RF_Ordered_No_Boot'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'RF_Ordered_No_Boot_Price_Direction'] = Price_Direction\n",
    "        \n",
    "        ### Calculating the difference between the Best_Ada_Predict_Shuffled - Close:\n",
    "        Difference_Prediction_Close = p['Best_Ada_Predict_Shuffled'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Ada_Shuffled_Close'] = Difference_Prediction_Close\n",
    "\n",
    "        ### Calculating the difference between the Label - Best_Ada_Predict_Shuffled:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Ada_Predict_Shuffled']\n",
    "        predictions_df.loc[q, 'Difference_Label_Ada_Shuffled'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'Ada_Shuffled_Price_Direction'] = Price_Direction\n",
    "\n",
    "        ### Calculating the difference between the Best_Ada_Predict_Ordered - Close:\n",
    "        Difference_Prediction_Close = p['Best_Ada_Predict_Ordered'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Ada_Ordered_Close'] = Difference_Prediction_Close\n",
    "        \n",
    "        ### Calculating the difference between the Label - Best_Ada_Predict_Shuffled:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Ada_Predict_Ordered']\n",
    "        predictions_df.loc[q, 'Difference_Label_Ada_Ordered'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'Ada_Ordered_Price_Direction'] = Price_Direction\n",
    "\n",
    "        ### Calculating the difference between the Best_Gradient_Boosting_Predict_Shuffled - Close:\n",
    "        Difference_Prediction_Close = p['Best_Gradient_Boosting_Predict_Shuffled'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Gradient_Boosting_Shuffled_Close'] = Difference_Prediction_Close\n",
    "\n",
    "        ### Calculating the difference between the Label - Best_Ada_Predict_Shuffled:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Gradient_Boosting_Predict_Shuffled']\n",
    "        predictions_df.loc[q, 'Difference_Label_Gradient_Boosting_Shuffled'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'Gradient_Boosting_Shuffled_Price_Direction'] = Price_Direction\n",
    "\n",
    "        ### Calculating the difference between the Best_Gradient_Boosting_Predict_Ordered - Close:\n",
    "        Difference_Prediction_Close = p['Best_Gradient_Boosting_Predict_Ordered'] - p.Close\n",
    "        predictions_df.loc[q, 'Difference_Gradient_Boosting_Ordered_Close'] = Difference_Prediction_Close\n",
    "        \n",
    "        ### Calculating the difference between the Label - Best_Ada_Predict_Shuffled:\n",
    "        Difference_Label_Prediction = p.Label - p['Best_Gradient_Boosting_Predict_Ordered']\n",
    "        predictions_df.loc[q, 'Difference_Label_Gradient_Boosting_Ordered'] = Difference_Label_Prediction\n",
    "\n",
    "\n",
    "        ### If the Difference_Label_Close is negative/positive & Difference_Prediction_Close is the same = 1:\n",
    "        if Difference_Label_Close > 0 and Difference_Prediction_Close > 0: \n",
    "            Price_Direction = 1\n",
    "\n",
    "        elif Difference_Label_Close < 0 and Difference_Prediction_Close < 0:\n",
    "            Price_Direction = 1\n",
    "\n",
    "        else:\n",
    "            Price_Direction = 0\n",
    "\n",
    "        predictions_df.loc[q, 'Gradient_Boosting_Ordered_Price_Direction'] = Price_Direction\n",
    "\n",
    "\n",
    "    stats_df = pandas.DataFrame({'Symbol': symbol, 'Name': name, \n",
    "                                 'Correct_Price_Movement_Average': numpy.nanmean(list(predictions_df['Average_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_RF_Shuffled': numpy.nanmean(list(predictions_df['RF_Shuffled_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_RF_Ordered': numpy.nanmean(list(predictions_df['RF_Ordered_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_RF_Ordered_No_Bootstrap': numpy.nanmean(list(predictions_df['RF_Ordered_No_Boot_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_Ada_Shuffled': numpy.nanmean(list(predictions_df['Ada_Shuffled_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_Ada_Ordered': numpy.nanmean(list(predictions_df['Ada_Ordered_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_Gradient_Boosting_Shuffled': numpy.nanmean(list(predictions_df['Gradient_Boosting_Shuffled_Price_Direction'].values)),\n",
    "                                 'Correct_Price_Movement_Gradient_Boosting_Ordered': numpy.nanmean(list(predictions_df['Gradient_Boosting_Ordered_Price_Direction'].values)),\n",
    "                                 'Average_Difference_Average_Close': numpy.nanmean(list(predictions_df['Difference_Average_Close'].values)),\n",
    "                                 'Average_Difference_RF_Shuffled_Close': numpy.nanmean(list(predictions_df['Difference_RF_Shuffled_Close'].values)),\n",
    "                                 'Average_Difference_RF_Ordered_Close': numpy.nanmean(list(predictions_df['Difference_RF_Ordered_Close'].values)),\n",
    "                                 'Average_Difference_RF_Ordered_No_Bootstrap_Close': numpy.nanmean(list(predictions_df['Difference_RF_Ordered_No_Boot_Close'].values)),\n",
    "                                 'Average_Difference_Ada_Shuffled_Close': numpy.nanmean(list(predictions_df['Difference_Ada_Shuffled_Close'].values)),\n",
    "                                 'Average_Difference_Ada_Ordered_Close': numpy.nanmean(list(predictions_df['Difference_Ada_Ordered_Close'].values)),\n",
    "                                 'Average_Difference_Gradient_Boosting_Shuffled_Close': numpy.nanmean(list(predictions_df['Difference_Gradient_Boosting_Shuffled_Close'].values)),\n",
    "                                 'Average_Difference_Gradient_Boosting_Ordered_Close': numpy.nanmean(list(predictions_df['Difference_Gradient_Boosting_Ordered_Close'].values)),\n",
    "                                 'Average_Difference_Label_Average': numpy.nanmean(list(predictions_df['Difference_Label_Average'].values)),\n",
    "                                 'Average_Difference_Label_RF_Shuffled': numpy.nanmean(list(predictions_df['Difference_Label_RF_Shuffled'].values)),\n",
    "                                 'Average_Difference_Label_RF_Ordered': numpy.nanmean(list(predictions_df['Difference_Label_RF_Ordered'].values)),\n",
    "                                 'Average_Difference_Label_RF_Ordered_No_Bootstrap': numpy.nanmean(list(predictions_df['Difference_Label_RF_Ordered_No_Boot'].values)),\n",
    "                                 'Average_Difference_Label_Ada_Shuffled': numpy.nanmean(list(predictions_df['Difference_Label_Ada_Shuffled'].values)),\n",
    "                                 'Average_Difference_Label_Ada_Ordered': numpy.nanmean(list(predictions_df['Difference_Label_Ada_Ordered'].values)),\n",
    "                                 'Average_Difference_Label_Gradient_Boosting_Shuffled': numpy.nanmean(list(predictions_df['Difference_Label_Gradient_Boosting_Shuffled'].values)),\n",
    "                                 'Average_Difference_Label_Gradient_Boosting_Ordered': numpy.nanmean(list(predictions_df['Difference_Label_Gradient_Boosting_Ordered'].values)),\n",
    "                                 'Absolute_Average_Difference_Label_Average': numpy.nanmean(list(abs(predictions_df['Difference_Label_Average'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_RF_Shuffled': numpy.nanmean(list(abs(predictions_df['Difference_Label_RF_Shuffled'].values))),\n",
    "                                 'Absolute_Average_Difference_Labelt_RF_Ordered': numpy.nanmean(list(abs(predictions_df['Difference_Label_RF_Ordered'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_RF_Ordered_No_Bootstrap': numpy.nanmean(list(abs(predictions_df['Difference_Label_RF_Ordered_No_Boot'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_Ada_Shuffled': numpy.nanmean(list(abs(predictions_df['Difference_Label_Ada_Shuffled'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_Ada_Ordered': numpy.nanmean(list(abs(predictions_df['Difference_Label_Ada_Ordered'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_Gradient_Boosting_Shuffled': numpy.nanmean(list(abs(predictions_df['Difference_Label_Gradient_Boosting_Shuffled'].values))),\n",
    "                                 'Absolute_Average_Difference_Label_Gradient_Boosting_Ordered': numpy.nanmean(list(abs(predictions_df['Difference_Label_Gradient_Boosting_Ordered'].values))),\n",
    "                                 'STD_Difference_Label_Average': numpy.nanstd(list(predictions_df['Difference_Label_Average'].values)),\n",
    "                                 'STD_Difference_Label_RF_Shuffled': numpy.nanstd(list(predictions_df['Difference_Label_RF_Shuffled'].values)),\n",
    "                                 'STD_Difference_Label_RF_Ordered': numpy.nanstd(list(predictions_df['Difference_Label_RF_Ordered'].values)),\n",
    "                                 'STD_Difference_Label_RF_Ordered_No_Bootstrap': numpy.nanstd(list(predictions_df['Difference_Label_RF_Ordered_No_Boot'].values)),\n",
    "                                 'STD_Difference_Label_Ada_Shuffled': numpy.nanstd(list(predictions_df['Difference_Label_Ada_Shuffled'].values)),\n",
    "                                 'STD_Difference_Label_Ada_Ordered': numpy.nanstd(list(predictions_df['Difference_Label_Ada_Ordered'].values)),\n",
    "                                 'STD_Difference_Label_Gradient_Boosting_Shuffled': numpy.nanstd(list(predictions_df['Difference_Label_Gradient_Boosting_Shuffled'].values)),\n",
    "                                 'STD_Difference_Label_Gradient_Boosting_Ordered': numpy.nanstd(list(predictions_df['Difference_Label_Gradient_Boosting_Ordered'].values)),\n",
    "                                 'Accuracy_Average': numpy.nanmean([best_random_forest_accuracy_score_shuffled,best_random_forest_accuracy_score_ordered,best_random_forest_accuracy_score_ordered_no_boot,best_ada_forest_accuracy_score_shuffled,best_ada_accuracy_score_ordered,best_gradient_boosting_accuracy_score_shuffled,best_gradient_boosting_accuracy_score_ordered]),\n",
    "                                 'Accuracy_RF_Shuffled': best_random_forest_accuracy_score_shuffled,\n",
    "                                 'Accuracy_RF_Ordered': best_random_forest_accuracy_score_ordered,\n",
    "                                 'Accuracy_RF_Ordered_No_Bootstrap': best_random_forest_accuracy_score_ordered_no_boot,\n",
    "                                 'Accuracy_Ada_Shuffled': best_ada_forest_accuracy_score_shuffled,\n",
    "                                 'Accuracy_Ada_Ordered': best_ada_accuracy_score_ordered,\n",
    "                                 'Accuracy_Gradient_Boosting_Shuffled': best_gradient_boosting_accuracy_score_shuffled,\n",
    "                                 'Accuracy_Gradient_Boosting_Ordered': best_gradient_boosting_accuracy_score_ordered}, index=[symbol])\n",
    "\n",
    "    if not os.path.exists(os.getcwd() + '\\\\Prediction Analysis\\\\'):\n",
    "        os.makedirs(os.getcwd() + '\\\\Prediction Analysis\\\\')\n",
    "\n",
    "    predictions_df.to_csv(os.getcwd() + '\\\\Prediction Analysis\\\\'  + symbol + ' - ' + name + ' - Prediction Analysis.csv')\n",
    "    stats_df.to_csv(os.getcwd() + '\\\\Prediction Analysis\\\\'  + symbol + ' - ' + name + ' - Prediction Statistics.csv')\n",
    "    features_df.to_csv(os.getcwd() + '\\\\Prediction Analysis\\\\'  + symbol + ' - ' + name + ' - Feature Importance.csv')\n",
    "    \n",
    "    return stats_df, features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looping:\n",
    "stocks_and_names_with_indices = pandas.read_csv('merged_NYSE_AMEX_removed_intercept_pattern.csv')\n",
    "\n",
    "for x, y in stocks_and_names_with_indices.iterrows():\n",
    "    try:\n",
    "        if x == 0:\n",
    "            combined_stats_df, combined_features_df = prediction_analysis(symbol=y['Symbol'], name=y['Description'])  \n",
    "\n",
    "        else:\n",
    "            stats_temp_df, features_temp_df = prediction_analysis(symbol=y['Symbol'], name=y['Description'])  \n",
    "            combined_stats_df = pandas.concat([combined_stats_df, stats_temp_df])\n",
    "            combined_features_df = pandas.concat([combined_features_df, features_temp_df])\n",
    "\n",
    "    except Exception:\n",
    "        print('Error: ', y['Symbol'], y['Description'])\n",
    "        pass\n",
    "        \n",
    "combined_stats_df = combined_stats_df.drop_duplicates()\n",
    "combined_features_df = combined_features_df.drop_duplicates()\n",
    "\n",
    "combined_stats_df.to_csv(os.getcwd() + '\\\\Prediction Analysis\\\\Overall Statistics.csv')\n",
    "combined_features_df.to_csv(os.getcwd() + '\\\\Prediction Analysis\\\\Overall Feature Importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
